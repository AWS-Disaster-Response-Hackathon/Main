{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567b4eac-78a5-47c9-9b83-81c30b3ab1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e83417-deea-4c2f-b6ae-0941d3613fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b917a7-04c6-4a76-b0a8-31ec291b3318",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flood = pd.read_csv(\"/home/studio-lab-user/sagemaker-studiolab-notebooks/DATA/flood_data.csv\", sep=\",\",encoding='latin-1')\n",
    "\n",
    "data_non_flood = pd.read_csv(\"/home/studio-lab-user/sagemaker-studiolab-notebooks/DATA/non-flood.csv\", sep=\",\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2887f8-a619-43d5-8f1a-80e445ff4dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Rain  Flood\n",
      "7    357.3      1\n",
      "150  170.4      0\n",
      "125  287.6      0\n",
      "76   310.6      1\n",
      "78   310.6      1\n",
      "..     ...    ...\n",
      "164   72.6      0\n",
      "176  354.0      0\n",
      "153  309.0      0\n",
      "81   183.9      1\n",
      "142  115.3      0\n",
      "\n",
      "[196 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([data_flood, data_non_flood], ignore_index=True).sample(frac=1)[[\"Rain\", \"Flood\"]]\n",
    "print(data)\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4111caf-9b84-4805-b480-05edce267589",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0].reshape(-1,1)\n",
    "y = data[:, 1].reshape(-1,1)\n",
    "#print(x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "602513cc-b7ec-4bcd-a462-754b26899eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 23:31:06.671851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-29 23:31:06.671950: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-29 23:31:06.671981: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2021-12-29 23:31:06.673730: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=1, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb4f04f0-e3ff-4da8-a419-89e168b97ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "49/49 [==============================] - 1s 1ms/step - loss: 0.7275 - accuracy: 0.6735\n",
      "Epoch 2/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.6531\n",
      "Epoch 3/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6633\n",
      "Epoch 4/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.6531\n",
      "Epoch 5/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.6429\n",
      "Epoch 6/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.8082 - accuracy: 0.6378\n",
      "Epoch 7/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6735\n",
      "Epoch 8/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6480\n",
      "Epoch 9/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6582\n",
      "Epoch 10/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6633\n",
      "Epoch 11/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.7452 - accuracy: 0.6582\n",
      "Epoch 12/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.6327\n",
      "Epoch 13/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.7462 - accuracy: 0.6582\n",
      "Epoch 14/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.7747 - accuracy: 0.6429\n",
      "Epoch 15/60\n",
      "49/49 [==============================] - 0s 981us/step - loss: 0.6579 - accuracy: 0.6480\n",
      "Epoch 16/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6480\n",
      "Epoch 17/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.6531\n",
      "Epoch 18/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6939\n",
      "Epoch 19/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6480\n",
      "Epoch 20/60\n",
      "49/49 [==============================] - 0s 996us/step - loss: 0.6496 - accuracy: 0.6786\n",
      "Epoch 21/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6276\n",
      "Epoch 22/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.6429\n",
      "Epoch 23/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.6327\n",
      "Epoch 24/60\n",
      "49/49 [==============================] - 0s 997us/step - loss: 0.6627 - accuracy: 0.6020\n",
      "Epoch 25/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.6939\n",
      "Epoch 26/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.6480\n",
      "Epoch 27/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.6582\n",
      "Epoch 28/60\n",
      "49/49 [==============================] - 0s 980us/step - loss: 0.6666 - accuracy: 0.6173\n",
      "Epoch 29/60\n",
      "49/49 [==============================] - 0s 976us/step - loss: 0.6373 - accuracy: 0.6276\n",
      "Epoch 30/60\n",
      "49/49 [==============================] - 0s 980us/step - loss: 0.6811 - accuracy: 0.6684\n",
      "Epoch 31/60\n",
      "49/49 [==============================] - 0s 956us/step - loss: 0.7166 - accuracy: 0.5918\n",
      "Epoch 32/60\n",
      "49/49 [==============================] - 0s 975us/step - loss: 0.6291 - accuracy: 0.6990\n",
      "Epoch 33/60\n",
      "49/49 [==============================] - 0s 963us/step - loss: 0.6175 - accuracy: 0.6582\n",
      "Epoch 34/60\n",
      "49/49 [==============================] - 0s 990us/step - loss: 0.6796 - accuracy: 0.6378\n",
      "Epoch 35/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.6633\n",
      "Epoch 36/60\n",
      "49/49 [==============================] - 0s 988us/step - loss: 0.6562 - accuracy: 0.6531\n",
      "Epoch 37/60\n",
      "49/49 [==============================] - 0s 986us/step - loss: 0.6400 - accuracy: 0.6837\n",
      "Epoch 38/60\n",
      "49/49 [==============================] - 0s 991us/step - loss: 0.7266 - accuracy: 0.6020\n",
      "Epoch 39/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.6276\n",
      "Epoch 40/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6325 - accuracy: 0.6684\n",
      "Epoch 41/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.6786\n",
      "Epoch 42/60\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6480\n",
      "Epoch 43/60\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.6735\n",
      "Epoch 44/60\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.6531\n",
      "Epoch 45/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6429\n",
      "Epoch 46/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6071\n",
      "Epoch 47/60\n",
      "49/49 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6837\n",
      "Epoch 48/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6684\n",
      "Epoch 49/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6633\n",
      "Epoch 50/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.6633\n",
      "Epoch 51/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.6582\n",
      "Epoch 52/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6429\n",
      "Epoch 53/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6582\n",
      "Epoch 54/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.6276\n",
      "Epoch 55/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6684\n",
      "Epoch 56/60\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6531\n",
      "Epoch 57/60\n",
      "49/49 [==============================] - 0s 978us/step - loss: 0.6846 - accuracy: 0.6429\n",
      "Epoch 58/60\n",
      "49/49 [==============================] - 0s 986us/step - loss: 0.6790 - accuracy: 0.6224\n",
      "Epoch 59/60\n",
      "49/49 [==============================] - 0s 984us/step - loss: 0.7369 - accuracy: 0.6429\n",
      "Epoch 60/60\n",
      "49/49 [==============================] - 0s 993us/step - loss: 0.7073 - accuracy: 0.6276\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7662 - accuracy: 0.4847\n",
      "Accuracy: 48.47\n"
     ]
    }
   ],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=60, batch_size=4)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1608fbe7-7b88-4065-967a-b71cb3976454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203/428078817.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(train_features, train_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[[1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      "  1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.]]\n",
      "Accuracy of Model 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13,  3],\n",
       "       [ 3, 21]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(bootstrap=True,max_depth=66, max_features='sqrt',\n",
    "                                 min_samples_leaf=1, min_samples_split=2,\n",
    "                                 n_estimators=452)\n",
    "\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "pred_labels_encoded = lab_enc.fit_transform(test_labels)\n",
    "    \n",
    "preds = clf.predict(test_features)\n",
    "print(preds)\n",
    "print(test_labels.reshape(1,-1))\n",
    "acc = accuracy_score(test_labels, preds)\n",
    "print(f'Accuracy of Model {acc}')\n",
    "\n",
    "confusion_matrix(test_labels, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e5322ae1-48d0-4b70-ac80-b4e55b891ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\n    # Number of trees in random forest\\n    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num = 10)]\\n    # Number of features to consider at every split\\n    max_features = ['auto', 'sqrt']\\n    # Maximum number of levels in tree\\n    max_depth = [int(x) for x in np.linspace(1, 110, num = 11)]\\n    max_depth.append(None)\\n    # Minimum number of samples required to split a node\\n    min_samples_split = [2, 5, 10]\\n    # Minimum number of samples required at each leaf node\\n    min_samples_leaf = [1, 2, 4]\\n    # Method of selecting samples for training each tree\\n    bootstrap = [True, False]\\n\\n    random_grid = {'n_estimators': n_estimators,\\n                   'max_features': max_features,\\n                   'max_depth': max_depth,\\n                   'min_samples_split': min_samples_split,\\n                   'min_samples_leaf': min_samples_leaf,\\n                   'bootstrap': bootstrap}\\n    rf = RandomForestClassifier()\\n\\n    lab_enc = preprocessing.LabelEncoder()\\n    train_labels_encoded = lab_enc.fit_transform(train_labels)\\n\\n    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = 4)\\n    rf_random.fit(train_features, train_labels_encoded)\\n    print (rf_random.best_params_)\\n\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''    \n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(1, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    lab_enc = preprocessing.LabelEncoder()\n",
    "    train_labels_encoded = lab_enc.fit_transform(train_labels)\n",
    "\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = 4)\n",
    "    rf_random.fit(train_features, train_labels_encoded)\n",
    "    print (rf_random.best_params_)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aef724-1743-4b5c-9119-f1462d3811e2",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
